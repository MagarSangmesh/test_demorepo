{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lgld70GiGPi",
        "outputId": "7d1de70b-b8cb-4b36-e960-4493d481f30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "n71zHphTyOlk",
        "outputId": "3595c06a-b0bd-489c-a1a5-53984a5ff19c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing folder 0: 100%|██████████| 501/501 [00:13<00:00, 37.25it/s] \n",
            "Processing folder 1: 100%|██████████| 2745/2745 [01:40<00:00, 27.31it/s] \n",
            "Processing folder 2: 100%|██████████| 501/501 [00:14<00:00, 35.60it/s] \n",
            "Processing folder 3: 100%|██████████| 501/501 [00:11<00:00, 45.23it/s] \n",
            "Processing folder 4: 100%|██████████| 501/501 [00:13<00:00, 36.34it/s] \n",
            "Processing folder 5: 100%|██████████| 501/501 [00:11<00:00, 42.92it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 5245 images.\n",
            "Validation Accuracy: 52.72%\n",
            "Test Accuracy: 51.48%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.03      0.05       103\n",
            "           1       0.52      0.98      0.68       534\n",
            "           2       0.00      0.00      0.00       104\n",
            "           3       0.00      0.00      0.00        87\n",
            "           4       1.00      0.01      0.02       119\n",
            "           5       0.39      0.13      0.19       102\n",
            "\n",
            "    accuracy                           0.51      1049\n",
            "   macro avg       0.36      0.19      0.16      1049\n",
            "weighted avg       0.44      0.51      0.37      1049\n",
            "\n",
            "[[  3  95   0   0   0   5]\n",
            " [  3 523   2   0   0   6]\n",
            " [  1 100   0   0   0   3]\n",
            " [  2  81   1   0   0   3]\n",
            " [  1 114   0   0   1   3]\n",
            " [  4  85   0   0   0  13]]\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from flask import Flask, request, jsonify\n",
        "from werkzeug.utils import secure_filename\n",
        "# ---Data download and preprocessing.\n",
        "# here, i have used cv2 for image processing & i am making a  user defined function to load images and labels\n",
        "def load_images_from_folders(folders):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label, folder in enumerate(folders):\n",
        "        for filename in tqdm(os.listdir(folder), desc=f\"Processing folder {label}\"):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "# here, i am  Resizing to a fixed size if needed\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (32, 32))\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "    print(f\"Loaded {len(images)} images.\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Updating the folder paths based on where my images are stored\n",
        "folders = [\n",
        "    '/content/drive/MyDrive/Bombaysoftware/dataset/dataset_full/Building',\n",
        "    '/content/drive/MyDrive/Bombaysoftware/dataset/dataset_full/Forest',\n",
        "    '/content/drive/MyDrive/Bombaysoftware/dataset/dataset_full/Glacier',\n",
        "    '/content/drive/MyDrive/Bombaysoftware/dataset/dataset_full/Mountains',\n",
        "    '/content/drive/MyDrive/Bombaysoftware/dataset/dataset_full/Sea',\n",
        "    '/content/drive/MyDrive/Bombaysoftware/dataset/dataset_full/Streets'\n",
        "]\n",
        "\n",
        "X, y = load_images_from_folders(folders)\n",
        "\n",
        "if len(X) == 0:\n",
        "    raise ValueError(\"No images loaded. Check the folder paths and structure.\")\n",
        "# Normalizing the images for overfitting problem\n",
        "X = X.astype('float32') / 255.0\n",
        "\n",
        "# Spliting the dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# i am making the user defined function to extract features\n",
        "def extract_features(images):\n",
        "    features = []\n",
        "    for img in images:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        if gray.dtype != np.uint8:\n",
        "            gray = gray.astype(np.uint8)\n",
        "\n",
        "        hist_eq = cv2.equalizeHist(gray).flatten()\n",
        "\n",
        "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5).flatten()\n",
        "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5).flatten()\n",
        "\n",
        "        canny = cv2.Canny(gray, 100, 200).flatten()\n",
        "\n",
        "        combined_features = np.hstack([hist_eq, sobelx, sobely, canny])\n",
        "        features.append(combined_features)\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "\n",
        "# here, i am doing feature extraction\n",
        "X_train_features = extract_features(X_train)\n",
        "X_val_features = extract_features(X_val)\n",
        "X_test_features = extract_features(X_test)\n",
        "\n",
        "# dimensionality reduction using PCA\n",
        "pca = PCA(n_components=100)\n",
        "X_train_pca = pca.fit_transform(X_train_features)\n",
        "X_val_pca = pca.transform(X_val_features)\n",
        "X_test_pca = pca.transform(X_test_features)\n",
        "\n",
        "# Classification algorithm of your choice with explanation.\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# evaluating on the validation set\n",
        "val_accuracy = clf.score(X_val_pca, y_val)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluation components.\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "test_accuracy = clf.score(X_test_pca, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# flask app: One should be able to upload an image and get the classification result.\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/classify', methods=['POST'])\n",
        "def classify_image():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image uploaded'}), 400\n",
        "\n",
        "    file = request.files['image']\n",
        "    filename = secure_filename(file.filename)\n",
        "    file_path = os.path.join('uploads', filename)\n",
        "    file.save(file_path)\n",
        "\n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    features = extract_features([img])\n",
        "    features_pca = pca.transform(features)\n",
        "    prediction = clf.predict(features_pca)\n",
        "\n",
        "    return jsonify({'class': int(prediction[0])})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.makedirs('uploads', exist_ok=True)\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ1VPskOhP6S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}